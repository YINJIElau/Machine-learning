{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP47750 Machine Learning Assignment\n",
    "# Gaussian Naive Bayes\n",
    "A reimplementation of the `sklearn` Gaussian Naive Bayes classifier. \n",
    "\n",
    "1. Provide a python class MyGaussianNB that implements Gaussian Naive Bayes. \n",
    "The API specification for sklearn classifiers is here: https://scikit-learn.org/stable/developers/develop.html \n",
    "You should implement the ‘fit’ and ‘predict’ methods, there is no need to implement ‘predict_proba’. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My GaussianNB\n",
    "Reimplementation of a Gaussian Naive Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGaussianNB(BaseEstimator, ClassifierMixin):          \n",
    "    def fit(self, Xt, yt):\n",
    "        self.var_smoothing = 1e-9\n",
    "        self.Xt = Xt\n",
    "        self.yt = yt\n",
    "        self.n_feat = Xt.shape[1]\n",
    "        # print(Xt)  how many rows and columns there are (4 columns)\n",
    "        # print(Xt.shape[1])  output 4\n",
    "        self.mus = {}\n",
    "        self.sig_sqs = {}\n",
    "        self.priors = {}\n",
    "        self.number = 0\n",
    "        \n",
    "        c_dict = Counter(self.yt)\n",
    "        # print(c_dict)  Counter({'Adelie': 76, 'Gentoo': 56, 'Chinstrap': 34})\n",
    "        # Mus and sig_sqs are stored by calculating their four characteristics for different result categories.\n",
    "        \n",
    "        for c in c_dict.keys():\n",
    "            self.mus[c] = np.zeros(self.n_feat) # where the means will be stored\n",
    "            self.sig_sqs[c] = np.zeros(self.n_feat) # where the variances will be stored\n",
    "            self.priors[c] = c_dict[c]/Xt.shape[0]\n",
    "            \n",
    "            mask = self.yt == c\n",
    "            X_tr_c = self.Xt[mask, :] # the rows for this class label\n",
    "            # print(X_tr_c)\n",
    "            \n",
    "            for f in range(self.n_feat):\n",
    "                \n",
    "                # Determine whether it is nan or not,nan value will be ignored\n",
    "                lst = filter(lambda x: np.isnan(x) == False, X_tr_c[:,f])\n",
    "                lst = list(lst)\n",
    "                self.number = self.number + (len(X_tr_c[:,f]) - len(lst))\n",
    "                # self.number is a quantity of missing values\n",
    "                print(self.number)\n",
    "                                                \n",
    "                self.mus[c][f] = np.mean(np.array(lst))\n",
    "                self.sig_sqs[c][f] = np.var(np.array(lst) + self.var_smoothing)\n",
    "        \n",
    "        # The limit warning on the number of missing values allowed\n",
    "        if (self.number >= 25):\n",
    "            print(\"After calculation, there are total \" + str(self.number) + \" missing values\")\n",
    "            print(\"Warning: there are to many missing values, Please try again.\")\n",
    "        else:\n",
    "            print(\"There are missing values less than 25.\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    # this function is to verify whether it's a number\n",
    "    def is_number(self, s):\n",
    "        try:\n",
    "            float(s)\n",
    "            return True\n",
    "        except ValueError:  \n",
    "            pass  \n",
    "        try:\n",
    "            import unicodedata \n",
    "            unicodedata.numeric(s)  \n",
    "            return True\n",
    "        except (TypeError, ValueError):\n",
    "            pass\n",
    "        return False\n",
    "    \n",
    "    # The predictions are the most common class in the training set.\n",
    "    def predict(self, Xtes):\n",
    "        self.Xtes = Xtes\n",
    "         \n",
    "        res_list = []\n",
    "        for sample in Xtes:\n",
    "            res_list.append(self.predict_single(sample))\n",
    "            \n",
    "        return np.array(res_list)\n",
    "    \n",
    "    def predict_single(self, x_single):\n",
    "        probs = {}\n",
    "        for c in self.priors.keys():   # for each of the class labels\n",
    "            probs[c] = self.priors[c]\n",
    "            for i, f in enumerate(x_single):\n",
    "                \n",
    "                # missing values will be set with nan in advance, if it is not nan, \n",
    "                # then it will be calculated for posterior probability calculation.\n",
    "                if(np.isnan(f)== False):\n",
    "                    t1 = 1/math.sqrt(2*math.pi*self.sig_sqs[c][i])\n",
    "                    num = (f - self.mus[c][i])**2\n",
    "                    den = 2*self.sig_sqs[c][i]\n",
    "                    pxi_y = t1 * math.exp(-num/den)\n",
    "                    probs[c] = probs[c] * pxi_y\n",
    "                    #print(t1, num, den, pxi_y)\n",
    "                    #print(probs)\n",
    "                    #print(c, self.priors[c])\n",
    "                else:\n",
    "                    pass\n",
    "            \n",
    "        return max(probs, key=probs.get) # Return the key with the largest value\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "2. Test the performance of your implementation against the `GaussianNB` implementation in `scikit-learn`. You should use a range of datasets for this testing.   \n",
    "Four datasets are used for testing; testing on a hold out set:\n",
    " - **penguins**: check that mean and variance estimates are the same, check that predictions are the same. \n",
    " - **diabetes**: check that predictions are the same.\n",
    " - **glassV2**: test that predictions are the same. \n",
    " - **bike_sharing**: test that predictions are the same. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Penguins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins = pd.read_csv('PenguinsMV0.4.csv', index_col = 0)\n",
    "\n",
    "# you can uncomment below command to run and test 0.4 data file.\n",
    "# penguins = pd.read_csv('PenguinsMV0.4.csv', index_col = 0)\n",
    "print(penguins.shape)\n",
    "penguins.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_names = ['bill_length_mm', 'bill_depth_mm','flipper_length_mm', 'body_mass_g']\n",
    "penguins = penguins[f_names + ['species']]\n",
    "penguins = penguins.loc[penguins['species'].isin(['Adelie','Chinstrap'])]\n",
    "# set species attribute to -1 position and only kepp Adelie and Chinstrap values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set all missing values with nan.\n",
    "\n",
    "def elementchange(list):\n",
    "    for element in list:\n",
    "        q = penguins[element].values\n",
    "        for i in range(len(q)):\n",
    "            if MyGaussianNB().is_number(q[i]):\n",
    "                pass\n",
    "            else:\n",
    "                penguins[element].values[i] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = penguins.pop('species').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elementchange(f_names)\n",
    "X_raw = penguins.values\n",
    "\n",
    "X_tr_raw, X_ts_raw, y_train, y_test = train_test_split(X_raw, y, random_state=2, test_size=1/2)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_tr_raw)\n",
    "X_test = scaler.transform(X_ts_raw)\n",
    "max_k = X_train.shape[1]\n",
    "\n",
    "# X_train = X_tr_raw\n",
    "# X_test = X_ts_raw\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.impute import *\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "#GaussianNB using missing value imputation\n",
    "\n",
    "imp = KNNImputer(missing_values = np.nan)\n",
    "imp.fit(X_tr_raw)\n",
    "X_train_G = imp.transform(X_tr_raw)\n",
    "X_test_G = imp.transform(X_ts_raw)\n",
    "\n",
    "\n",
    "imp2 = SimpleImputer(missing_values = np.nan, strategy='mean')\n",
    "imp2.fit(X_tr_raw)\n",
    "X_train_G2 = imp2.transform(X_tr_raw)\n",
    "X_test_G2 = imp2.transform(X_ts_raw)\n",
    "\n",
    "\n",
    "imp3 = IterativeImputer(max_iter=10, random_state=0)\n",
    "imp3.fit(X_tr_raw)\n",
    "X_train_G3 = imp3.transform(X_tr_raw)\n",
    "X_test_G3 = imp3.transform(X_ts_raw)\n",
    "# scaler = StandardScaler()\n",
    "# X_train_G = scaler.fit_transform(X_tr_raw)\n",
    "# X_test_G = scaler.transform(X_ts_raw)\n",
    "max_k_G = X_train_G.shape[1]\n",
    "\n",
    "X_train_G.shape, X_test_G.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines & Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "# the cross validation for KNN imputation\n",
    "kNNpipe  = Pipeline(steps=[\n",
    "    ('imputer', KNNImputer(missing_values = np.nan)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', GaussianNB())])\n",
    "\n",
    "\n",
    "acc_arr = cross_val_score(kNNpipe, X_raw, y, cv=5, n_jobs = -1)\n",
    "print(\"Accuracy: {0:4.2f}\".format(sum(acc_arr)/len(acc_arr)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the cross validation for univariate imputation\n",
    "kNNpipe2  = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(missing_values = np.nan, strategy='mean')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', GaussianNB())])\n",
    "\n",
    "\n",
    "acc_arr2 = cross_val_score(kNNpipe2, X_raw, y, cv=5, n_jobs = -1)\n",
    "print(\"Accuracy: {0:4.2f}\".format(sum(acc_arr2)/len(acc_arr2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the cross validation for multi-variate imputation\n",
    "kNNpipe3  = Pipeline(steps=[\n",
    "    ('imputer', IterativeImputer(max_iter=10, random_state=0)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', GaussianNB())])\n",
    "\n",
    "\n",
    "acc_arr3 = cross_val_score(kNNpipe3, X_raw, y, cv=5, n_jobs = -1)\n",
    "print(\"Accuracy: {0:4.2f}\".format(sum(acc_arr3)/len(acc_arr3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the # the cross validation for my approach\n",
    "\n",
    "mkNNpipe  = Pipeline(steps=[\n",
    "    ('imputer', elementchange(f_names)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', MyGaussianNB())])\n",
    "\n",
    "\n",
    "macc_arr = cross_val_score(mkNNpipe, X_raw, y, cv=5, n_jobs = -1)\n",
    "print(\"Accuracy: {0:4.2f}\".format(sum(macc_arr)/len(macc_arr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracies for \"PenguinsMV0.4.csv\" file are 0.80(KNN imputation) and 0.83(my approach) respectively.\n",
    "\n",
    "The accuracies for \"PenguinsMV0.2.csv\" file are 0.95(KNN imputation) and 0.95(my approach) respectively.\n",
    "\n",
    "The accuracies for \"PenguinsMV0.2.csv\" file are 0.95(univariate imputation) and 0.95(univariate imputation) respectively.\n",
    "\n",
    "The accuracies for \"PenguinsMV0.4.csv\" file are 0.83(univariate imputation) and 0.80(univariate imputation) respectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Parameters**  \n",
    "The means are showed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train_G,y_train)\n",
    "\n",
    "gnb2 = GaussianNB()\n",
    "gnb2.fit(X_train_G2,y_train)\n",
    "\n",
    "gnb3 = GaussianNB()\n",
    "gnb3.fit(X_train_G3,y_train)\n",
    "\n",
    "\n",
    "mgnb = MyGaussianNB()\n",
    "mgnb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgnb.sig_sqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb.theta_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mgnb.mus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy scores are showed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gnb.score(X_test_G, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgnb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy scores for gnb and mgnb are 0.8037383177570093 and 0.8504672897196262   -------- PenguinsMV0.4.csv\n",
    "\n",
    "The accuracy scores for gnb and mgnb are 0.9626168224299065 and 0.9626168224299065   -------- PenguinsMV0.2.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb2.score(X_test_G2, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb3.score(X_test_G3, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The accuracy scores for gnb2 and gnb3 are 0.8691588785046729 and 0.8504672897196262 -------- PenguinsMV0.4.csv\n",
    "\n",
    "The accuracy scores for gnb2 and gnb3 are 0.9626168224299065 and 0.9626168224299065 -------- PenguinsMV0.2.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fidelity tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the lables of the predictions of the first 10 test samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mgnb.predict(X_test[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb.predict(X_test_G[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
