{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9934371",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af19bc1",
   "metadata": {},
   "source": [
    "## Read data and there are totally 333 data and every data have 8 attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e213f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "penguins_af = pd.read_csv('penguins_af.csv', index_col = 0) \n",
    "print(penguins_af.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc09cdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins_af"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f350824",
   "metadata": {},
   "source": [
    "# Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92af8da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_names = ['bill_length_mm', 'bill_depth_mm','flipper_length_mm', 'body_mass_g']\n",
    "penguins = penguins_af[f_names + ['species']]\n",
    "penguins2C = penguins.loc[penguins['species'].isin(['Adelie','Chinstrap'])]\n",
    "# set species attribute to -1 position and only kepp Adelie and Chinstrap values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4889bf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca070e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "penguins2C['species'] = labelencoder.fit_transform(penguins2C['species'])\n",
    "\n",
    "# Use LabelEncoder to convert two Category attributes to numbers(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21410f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins2C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4e4acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "data_df = penguins2C\n",
    "\n",
    "# Split data into trainset and testset(every part of 10 data has 7 traindata and 3 testdata)\n",
    "def splitData(data_list,ratio):\n",
    "  train_size = int(len(data_list)*ratio)\n",
    "  random.shuffle(data_list)\n",
    "  train_set = data_list[:train_size]\n",
    "  test_set = data_list[train_size:]\n",
    "  return train_set, test_set\n",
    "\n",
    "data_list = np.array(data_df).tolist()\n",
    "trainset,testset = splitData(data_list,ratio = 0.7)\n",
    "print('Split {0} samples into {1} train and {2} test samples '.format(len(data_df), len(trainset), len(testset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4812b4",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1468550",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seprateByClass(dataset):\n",
    "    seprate_dict = {}\n",
    "    info_dict = {}\n",
    "    for vector in dataset:\n",
    "        if vector[-1] not in seprate_dict:\n",
    "            seprate_dict[vector[-1]] = []\n",
    "            info_dict[vector[-1]] = 0\n",
    "        seprate_dict[vector[-1]].append(vector)\n",
    "        info_dict[vector[-1]] += 1\n",
    "    return seprate_dict, info_dict\n",
    "\n",
    "train_separated, train_info = seprateByClass(trainset)\n",
    "# classify data,train_separated includes two different category data and  train_info records number of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8264dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2efa43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calulateClassPriorProb(dataset,dataset_info):\n",
    "    dataset_prior_prob = {}\n",
    "    sample_sum = len(dataset)\n",
    "    for class_value, sample_nums in dataset_info.items():\n",
    "      dataset_prior_prob[class_value] = sample_nums/float(sample_sum)\n",
    "    return dataset_prior_prob\n",
    "\n",
    "prior_prob = calulateClassPriorProb(trainset, train_info)\n",
    "\n",
    "#this aims for calculating class probability, for example 0 class is 100/(100+49)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffa0e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c66f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(list):\n",
    "    list = [float(x) for x in list]\n",
    "    return sum(list) / float(len(list))\n",
    "\n",
    "\n",
    "def var(list):\n",
    "    list = [float(x) for x in list]\n",
    "    avg = mean(list)\n",
    "    var = sum([math.pow((x - avg), 2) for x in list]) / float(len(list) - 1)\n",
    "    return var\n",
    "\n",
    "# The conditional probabilities\n",
    "def calculateProb(x, mean, var):\n",
    "    exponent = math.exp(math.pow((x - mean), 2) / (-2 * var))\n",
    "    p = (1 / math.sqrt(2 * math.pi * var)) * exponent\n",
    "    return p\n",
    "\n",
    "def summarizeAttribute(dataset):\n",
    "    dataset = np.delete(dataset, -1, axis=1)  # delete label\n",
    "    summaries = [(mean(attr), var(attr)) for attr in zip(*dataset)]\n",
    "    return summaries\n",
    "\n",
    "summary = summarizeAttribute(trainset) # Calculate every attribute's mean and var\n",
    "\n",
    "def summarizeByClass(dataset):\n",
    "    dataset_separated, dataset_info = seprateByClass(dataset)\n",
    "    summarize_by_class = {}\n",
    "    for classValue, vector in dataset_separated.items():\n",
    "        summarize_by_class[classValue] = summarizeAttribute(vector)\n",
    "    return summarize_by_class\n",
    "\n",
    "train_Summary_by_class = summarizeByClass(trainset) # Calculate every attribute's mean and var based on class\n",
    "\n",
    "# Above methods are the fit method,being devided into several parts of calculations\n",
    "\n",
    "def calculateClassProb(input_data, train_Summary_by_class):\n",
    "    prob = {}\n",
    "    for class_value, summary in train_Summary_by_class.items():\n",
    "        prob[class_value] = 1\n",
    "        for i in range(len(summary)):\n",
    "            mean, var = summary[i]\n",
    "            x = input_data[i]\n",
    "            p = calculateProb(x, mean, var)\n",
    "            prob[class_value] *= p\n",
    "    return prob\n",
    "\n",
    "#Multiplies the conditional probabilities of each attribute by class.\n",
    "input_vector = testset[1]\n",
    "input_data = input_vector[:-1]\n",
    "train_Summary_by_class = summarizeByClass(trainset)\n",
    "class_prob = calculateClassProb(input_data, train_Summary_by_class)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dff6d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesianPredictOneSample(input_data):#predict single data\n",
    "    prior_prob = calulateClassPriorProb(trainset, train_info)\n",
    "    train_Summary_by_class = summarizeByClass(trainset)\n",
    "    classprob_dict = calculateClassProb(input_data, train_Summary_by_class)\n",
    "    result = {}\n",
    "    for class_value, class_prob in classprob_dict.items():\n",
    "        p = class_prob * prior_prob[class_value]\n",
    "        result[class_value] = p\n",
    "    return max(result, key=result.get)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5697d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e96094",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vector = testset[8]\n",
    "input_data = input_vector[:-1]\n",
    "result = bayesianPredictOneSample(input_data)\n",
    "print(\"the sameple is predicted to class: {0}.\".format(result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a33438",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateAccByBeyesian(dataset):\n",
    "  correct = 0\n",
    "  for vector in dataset:\n",
    "      input_data = vector[:-1]\n",
    "      label = vector[-1]\n",
    "      result = bayesianPredictOneSample(input_data)\n",
    "      if result == label:\n",
    "          correct+=1\n",
    "  return correct/len(dataset)\n",
    "\n",
    "acc = calculateAccByBeyesian(testset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c761c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The Accuracy of our Naive Bayes is:\",int(acc*100),\"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
